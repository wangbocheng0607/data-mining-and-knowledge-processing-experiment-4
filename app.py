import streamlit as st
import time
import os
os.environ['HF_HOME'] = './hf_cache'  # è®¾ç½®æ¨¡å‹ç¼“å­˜ç›®å½•
# ä¸è®¾ç½®HF_ENDPOINTï¼Œç¡®ä¿ä½¿ç”¨æœ¬åœ°æ¨¡å‹ 


# Import functions and config from other modules
from config import (
    DATA_FILE, EMBEDDING_MODEL_NAME, GENERATION_MODEL_NAME, TOP_K,
    MAX_ARTICLES_TO_INDEX, MILVUS_LITE_DATA_PATH, COLLECTION_NAME,
    id_to_doc_map, VECTOR_STORE_TYPE, CHROMA_PERSIST_DIRECTORY # Import the global map and vector store config
)
from data_utils import load_data
from models import load_embedding_model, load_generation_model
from rag_core import generate_answer

# Dynamically import vector store utilities based on configuration
if VECTOR_STORE_TYPE == "chromadb":
    from chromadb_utils import get_chroma_client, get_or_create_collection, index_data_if_needed, search_similar_documents
else:
    from milvus_utils import get_milvus_client, setup_milvus_collection, index_data_if_needed, search_similar_documents

# --- Streamlit UI è®¾ç½® ---
st.set_page_config(layout="wide")

# Dynamic UI based on vector store type
if VECTOR_STORE_TYPE == "chromadb":
    st.title("ğŸ“„ åŒ»ç–— RAG ç³»ç»Ÿ (ChromaDB)")
    st.markdown(f"ä½¿ç”¨ ChromaDB, `{EMBEDDING_MODEL_NAME}`, å’Œ `{GENERATION_MODEL_NAME}`ã€‚")
else:
    st.title("ğŸ“„ åŒ»ç–— RAG ç³»ç»Ÿ (Milvus Lite)")
    st.markdown(f"ä½¿ç”¨ Milvus Lite, `{EMBEDDING_MODEL_NAME}`, å’Œ `{GENERATION_MODEL_NAME}`ã€‚")

# --- åˆå§‹åŒ–ä¸ç¼“å­˜ ---
vector_store_client = None
collection_is_ready = False

# Initialize vector store client based on configuration
if VECTOR_STORE_TYPE == "chromadb":
    vector_store_client = get_chroma_client()
    if vector_store_client:
        collection_is_ready = get_or_create_collection(vector_store_client)
else:
    vector_store_client = get_milvus_client()
    if vector_store_client:
        collection_is_ready = setup_milvus_collection(vector_store_client)

# åŠ è½½æ¨¡å‹ (ç¼“å­˜) only if vector store client is available
if vector_store_client:
    embedding_model = load_embedding_model(EMBEDDING_MODEL_NAME)
    generation_model, tokenizer = load_generation_model(GENERATION_MODEL_NAME)

    # æ£€æŸ¥æ‰€æœ‰ç»„ä»¶æ˜¯å¦æˆåŠŸåŠ è½½
    models_loaded = embedding_model and generation_model and tokenizer

    if collection_is_ready and models_loaded:
        # åŠ è½½æ•°æ® (æœªç¼“å­˜)
        pubmed_data = load_data(DATA_FILE)

        # å¦‚æœéœ€è¦åˆ™ç´¢å¼•æ•°æ® (è¿™ä¼šå¡«å…… id_to_doc_map)
        if pubmed_data:
            indexing_successful = index_data_if_needed(vector_store_client, pubmed_data, embedding_model)
        else:
            st.warning(f"æ— æ³•ä» {DATA_FILE} åŠ è½½æ•°æ®ã€‚è·³è¿‡ç´¢å¼•ã€‚")
            indexing_successful = False # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œåˆ™è§†ä¸ºä¸æˆåŠŸ

        st.divider()

        # --- RAG äº¤äº’éƒ¨åˆ† ---
        if not indexing_successful and not id_to_doc_map:
             st.error("æ•°æ®ç´¢å¼•å¤±è´¥æˆ–ä¸å®Œæ•´ï¼Œä¸”æ²¡æœ‰æ–‡æ¡£æ˜ å°„ã€‚RAG åŠŸèƒ½å·²ç¦ç”¨ã€‚")
        else:
            query = st.text_input("è¯·æå‡ºå…³äºå·²ç´¢å¼•åŒ»ç–—æ–‡ç« çš„é—®é¢˜:", key="query_input")

            if st.button("è·å–ç­”æ¡ˆ", key="submit_button") and query:
                start_time = time.time()

                # 1. æœç´¢å‘é‡å­˜å‚¨
                with st.spinner("æ­£åœ¨æœç´¢ç›¸å…³æ–‡æ¡£..."):
                    retrieved_ids, distances = search_similar_documents(vector_store_client, query, embedding_model)

                if not retrieved_ids:
                    st.warning("åœ¨æ•°æ®åº“ä¸­æ‰¾ä¸åˆ°ç›¸å…³æ–‡æ¡£ã€‚")
                else:
                    # 2. ä»æ˜ å°„ä¸­æ£€ç´¢ä¸Šä¸‹æ–‡
                    retrieved_docs = [id_to_doc_map[id] for id in retrieved_ids if id in id_to_doc_map]

                    if not retrieved_docs:
                         st.error("æ£€ç´¢åˆ°çš„ ID æ— æ³•æ˜ å°„åˆ°åŠ è½½çš„æ–‡æ¡£ã€‚è¯·æ£€æŸ¥æ˜ å°„é€»è¾‘ã€‚")
                    else:
                        st.subheader("æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡æ–‡æ¡£:")
                        for i, doc in enumerate(retrieved_docs):
                            # å¦‚æœè·ç¦»å¯ç”¨åˆ™æ˜¾ç¤ºï¼Œå¦åˆ™åªæ˜¾ç¤º ID
                            dist_str = f", è·ç¦»: {distances[i]:.4f}" if distances else ""
                            with st.expander(f"æ–‡æ¡£ {i+1} (ID: {retrieved_ids[i]}{dist_str}) - {doc['title'][:60]}"):
                                st.write(f"**æ ‡é¢˜:** {doc['title']}")
                                st.write(f"**æ‘˜è¦:** {doc['abstract']}") # å‡è®¾ 'abstract' å­˜å‚¨çš„æ˜¯æ–‡æœ¬å—

                        st.divider()

                        # 3. ç”Ÿæˆç­”æ¡ˆ
                        st.subheader("ç”Ÿæˆçš„ç­”æ¡ˆ:")
                        with st.spinner("æ­£åœ¨æ ¹æ®ä¸Šä¸‹æ–‡ç”Ÿæˆç­”æ¡ˆ..."):
                            answer = generate_answer(query, retrieved_docs, generation_model, tokenizer)
                            st.write(answer)

                end_time = time.time()
                st.info(f"æ€»è€—æ—¶: {end_time - start_time:.2f} ç§’")

    else:
        if VECTOR_STORE_TYPE == "chromadb":
            st.error("åŠ è½½æ¨¡å‹æˆ–è®¾ç½® ChromaDB collection å¤±è´¥ã€‚è¯·æ£€æŸ¥æ—¥å¿—å’Œé…ç½®ã€‚")
        else:
            st.error("åŠ è½½æ¨¡å‹æˆ–è®¾ç½® Milvus Lite collection å¤±è´¥ã€‚è¯·æ£€æŸ¥æ—¥å¿—å’Œé…ç½®ã€‚")
else:
    if VECTOR_STORE_TYPE == "chromadb":
        st.error("åˆå§‹åŒ– ChromaDB å®¢æˆ·ç«¯å¤±è´¥ã€‚è¯·æ£€æŸ¥æ—¥å¿—ã€‚")
    else:
        st.error("åˆå§‹åŒ– Milvus Lite å®¢æˆ·ç«¯å¤±è´¥ã€‚è¯·æ£€æŸ¥æ—¥å¿—ã€‚")


# --- é¡µè„š/ä¿¡æ¯ä¾§è¾¹æ  ---
st.sidebar.header("ç³»ç»Ÿé…ç½®")
if VECTOR_STORE_TYPE == "chromadb":
    st.sidebar.markdown(f"**å‘é‡å­˜å‚¨:** ChromaDB")
    st.sidebar.markdown(f"**æ•°æ®è·¯å¾„:** `{CHROMA_PERSIST_DIRECTORY}`")
else:
    st.sidebar.markdown(f"**å‘é‡å­˜å‚¨:** Milvus Lite")
    st.sidebar.markdown(f"**æ•°æ®è·¯å¾„:** `{MILVUS_LITE_DATA_PATH}`")
st.sidebar.markdown(f"**Collection:** `{COLLECTION_NAME}`")
st.sidebar.markdown(f"**æ•°æ®æ–‡ä»¶:** `{DATA_FILE}`")
st.sidebar.markdown(f"**åµŒå…¥æ¨¡å‹:** `{EMBEDDING_MODEL_NAME}`")
st.sidebar.markdown(f"**ç”Ÿæˆæ¨¡å‹:** `{GENERATION_MODEL_NAME}`")
st.sidebar.markdown(f"**æœ€å¤§ç´¢å¼•æ•°:** `{MAX_ARTICLES_TO_INDEX}`")
st.sidebar.markdown(f"**æ£€ç´¢ Top K:** `{TOP_K}`")